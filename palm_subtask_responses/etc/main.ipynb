{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Pratham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import google.generativeai as palm\n",
    "import numpy as np\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "\n",
    "my_config = json.load(open('config.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "palm.configure(api_key=my_config['palm_api_key'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/text-bison-001\n"
     ]
    }
   ],
   "source": [
    "models = [m for m in palm.list_models() if 'generateText' in m.supported_generation_methods]\n",
    "model = models[0].name\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_model = \"models/embedding-gecko-001\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "\n",
    "from google.auth.transport.requests import Request\n",
    "from google.oauth2.credentials import Credentials\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "\n",
    "SCOPES = ['https://www.googleapis.com/auth/generative-language.tuning']\n",
    "\n",
    "def load_creds():\n",
    "    \"\"\"Converts `oauth-client-id.json` to a credential object.\n",
    "    \n",
    "    This function caches the generated tokens to minimize the use of the\n",
    "    consent screen.\n",
    "    \"\"\"\n",
    "    creds = None\n",
    "    # The file token.json stores the user's access and refresh tokens, and is\n",
    "    # created automatically when the authorization flow completes for the first\n",
    "    # time.\n",
    "    if os.path.exists('token.json'):\n",
    "        creds = Credentials.from_authorized_user_file('token.json', SCOPES)\n",
    "    # If there are no (valid) credentials available, let the user log in.\n",
    "    if not creds or not creds.valid:\n",
    "        if creds and creds.expired and creds.refresh_token:\n",
    "            creds.refresh(Request())\n",
    "        else:\n",
    "            flow = InstalledAppFlow.from_client_secrets_file(\n",
    "                'client_secret_56510766963.json', SCOPES)\n",
    "            creds = flow.run_local_server(port=0)\n",
    "        # Save the credentials for the next run\n",
    "        with open('token.json', 'w') as token:\n",
    "            token.write(creds.to_json())\n",
    "    return creds\n",
    "\n",
    "# load_creds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "arg_prompt = \"\"\"\n",
    "I have a argument for an function call. I want to summarize it and get its data type and possible values.\n",
    "For Example:\n",
    "\n",
    "Input:{\"name\": \"ticket.severity\",\"description\": \"Filters for tickets with any of the provided severities. Allowed values: blocker, high, low, medium\",\"type\": \"array of strings\"}\n",
    "Ouput: {\"desc\": \"Filters for tickets with any of the provided severities\", \"type\": \"Array[String]\", \"allowed\": [\"blocker\", \"high\", \"low\", \"medium\"]}\n",
    "\n",
    "Input:{\"name\": \"query\",\"description\": \"The search string, could be for example customer's name, part name, user name.\",\"type\": \"string\"}\n",
    "Output: {\"desc\": \"The search string, could be for example customer's name, part name, user name.\", \"type\": \"String\"}\n",
    "\n",
    "Input: {\"name\": \"limit\",\"description\": \"The maximum number of works to return. The default is '50'\",\"type\": \"integer (int32)\"}\n",
    "Output: {\"desc\": \"The maximum number of works to return.\", \"type\": \"int32\"}\n",
    "\n",
    "Input: {\"name\": \"applies_to_part\", \"description\": \"Filters for work belonging to any of the provided parts\", \"type\": \"array of strings\", \"example\": [ \"FEAT-123\", \"ENH-123\", \"PROD-123\", \"CAPL-123\" ]}\n",
    "Output: {\"desc\": \"Filters for work belonging to any of the provided parts.\", \"type\": \"Array[String]\", \"example\": [\"FEAT-123\", \"ENH-123\", \"PROD-123\", \"CAPL-123\"]}\n",
    "\n",
    "solve for the following argument ensuring output is valid json:\n",
    "Input: %s\n",
    "Output:\n",
    "\"\"\"\n",
    "\n",
    "tools = json.load(open('tools.json'))\n",
    "arguments_description = {}\n",
    "\n",
    "if os.path.exists('refined_arguments_description.json'):\n",
    "    arguments_description = json.load(open('refined_arguments_description.json'))\n",
    "else:\n",
    "    for tool in tools[\"tools\"]:\n",
    "        arguments_description[tool[\"name\"]] = []\n",
    "        for argument in tool.get(\"arguments\" ,[]):\n",
    "            output = palm.generate_text(\n",
    "                model=model,\n",
    "                prompt=arg_prompt % argument,\n",
    "                temperature=0,\n",
    "                max_output_tokens=800,\n",
    "            )\n",
    "            arguments_description[tool[\"name\"]].append({argument[\"name\"]: eval(output.result)}) \n",
    "    json.dump(arguments_description, open('refined_arguments_description.json', 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "refined_arguments_description = json.load(open('refined_arguments_description.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KnowledgeItem:\n",
    "    description: str\n",
    "    tool: str\n",
    "\n",
    "    def __init__(self, description: str, tool: str) -> None:\n",
    "        self.description = description\n",
    "        self.tool = tool\n",
    "\n",
    "    def summarize(self) -> str:\n",
    "        return self.description + \":\" + self.tool\n",
    "    \n",
    "    def __str__(self) -> str:\n",
    "        return f\"Know <{self.description} from [{self.tool}]>\"\n",
    "    \n",
    "    def __repr__(self) -> str:\n",
    "        return str(self)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Know <the ID of the current sprint from [get_sprint_id]>, Know <the ID of the current user from [who_am_i]>]\n"
     ]
    }
   ],
   "source": [
    "knowledge = []\n",
    "\n",
    "l = list(refined_arguments_description.keys())\n",
    "\n",
    "for tool in refined_arguments_description:\n",
    "    if len(refined_arguments_description[tool]) == 0:\n",
    "        tool_names = [t['name'] for t in tools['tools']]\n",
    "        index = tool_names.index(tool)\n",
    "        tool_description = tools['tools'][index]['description'].split('Returns ')[1]\n",
    "        knowledge.append(KnowledgeItem(tool_description, tool))\n",
    "\n",
    "print(knowledge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "works_list:Returns a list of work items matching the request with args:\n",
      "\tapplies_to_part:Filters for work belonging to any of the provided parts\n",
      "summarize_objects:Summarizes a list of objects with args:\n",
      "\tobjects:List of objects to summarize\n",
      "prioritize_objects:Returns a list of objects sorted by priority with args:\n",
      "\tobjects:A list of objects to be prioritized\n",
      "add_work_items_to_sprint:Adds the given work items to the sprint with args:\n",
      "\twork_ids:A list of work item IDs to be added to the sprint\n",
      "get_sprint_id:Returns the ID of the current sprint\n",
      "get_similar_work_items:Returns a list of work items that are similar to the given work item with args:\n",
      "\twork_id:The ID of the work item for which you want to find similar items\n",
      "search_object_by_name:Given a search string, returns the id of a matching object in the system of record with args:\n",
      "\tquery:The search string, could be for example customer's name, part name, user name\n",
      "create_actionable_tasks_from_text:Given a text, extracts actionable insights, and creates tasks for them, which are kind of a work item with args:\n",
      "\ttext:The text from which the actionable insights need to be created\n",
      "who_am_i:Returns the ID of the current user\n",
      "1186\n"
     ]
    }
   ],
   "source": [
    "tools_description = \"\"\n",
    "\n",
    "for tool in tools[\"tools\"]:\n",
    "    tools_description += \"\\n\" + f\"{tool['name']}:{tool['description'].split('.')[0]}\" \n",
    "    for argument in refined_arguments_description[tool[\"name\"]][:1]:\n",
    "        tools_description += \" with args:\"\n",
    "        for arg, props in argument.items():\n",
    "            tools_description += f\"\\n\\t{arg}:{props['desc'].split('.')[0]}\"\n",
    "            # if 'example' in props.keys():\n",
    "            #     tools_description += f\" like: {props['example'][:2]}\"\n",
    "    \n",
    "\n",
    "\n",
    "print(tools_description)\n",
    "print(len(tools_description))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_getter_prompt = \"\"\"\n",
    "You are a bot for a company to manage their work items using some tools\n",
    "Here are some actions you can perform with the tool:%s\n",
    "\n",
    "Using these as context you solve the relevant tasks strictly using these actions in the correct context as follows\n",
    "\n",
    "Input: List all high severity tickets coming in from slack from customer Cust123 and generate a summary of them\n",
    "Output: [(\"Get objects from customer Cust123\",\"search_object_by_name\"),(\"List all high severity tickets coming in from slack from Cust123\",\"works_list\"),(\"Summarize the high severity tickets\",\"summarize_objects\")]\n",
    "\n",
    "Input: Given a customer meeting transcript T, create action items and add them to my current sprint\n",
    "Output: [(\"Create action items from T\",\"create_actionable_tasks_from_text\"),(\"Add action items to my current sprint\",\"add_tasks_to_sprint\")]\n",
    "\n",
    "Input: Prioritize my P0 issues and add them to the current sprint\n",
    "Output: [(\"Get my P0 issues\",\"works_list\"),(\"Prioritize my P0 issues\",\"prioritize_objects\"),(\"Add my P0 issues to the current sprint\",\"add_work_items_to_sprint\")]\n",
    "\n",
    "Input: What did the dog eat for breakfast?\n",
    "Output: []\n",
    "\n",
    "Give list for:\n",
    "Input: %s\n",
    "Output:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2421\n"
     ]
    }
   ],
   "source": [
    "input_prompt = \"\"\"What are my all issues in the triage stage under part FEAT-123? Summarize them.\"\"\"\n",
    "# '[(\"Get my issues in the triage stage under part FEAT-123\", \"works_list\"),(\"Summarize them\", \"summarize_objects\")]'\n",
    "\n",
    "input_prompt = \"\"\"Get all work items similar to TKT-123, summarize them, create issues from that summary, and prioritize them\"\"\"\n",
    "\n",
    "final_prompt = tool_getter_prompt % (tools_description, input_prompt)\n",
    "\n",
    "print(len(final_prompt))\n",
    "\n",
    "completion = palm.generate_text(\n",
    "    model=model,\n",
    "    prompt=final_prompt,\n",
    "    temperature=0,\n",
    "    max_output_tokens=800,\n",
    ")\n",
    "\n",
    "instructions0 = eval(completion.result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_prompt = \"\"\"List all high severity tickets coming in from slack from customer Cust123 and generate a summary of them.\"\"\"\n",
    "input_prompt = \"Retrieve work items in the 'In Progress' stage owned by 'USER-456' and 'USER-789', summarize them, and prioritize by severity.\"\n",
    "input_prompt = \"Get my work items\"\n",
    "completion = palm.generate_text(\n",
    "    model=model,\n",
    "    prompt=tool_getter_prompt % (tools_description,input_prompt),\n",
    "    temperature=0,\n",
    "    max_output_tokens=800,\n",
    ")\n",
    "\n",
    "instructions1 = eval(completion.result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Get my work items', 'works_list')]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instructions1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "instructions = eval(completion.result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def cosine_similarity(embeddings1, embeddings2):\n",
    "    vector1 = np.array(embeddings1)\n",
    "    vector2 = np.array(embeddings2)\n",
    "\n",
    "    # Calculate dot product\n",
    "    dot_product = np.dot(vector1, vector2)\n",
    "\n",
    "    # Calculate magnitudes\n",
    "    magnitude1 = np.linalg.norm(vector1)\n",
    "    magnitude2 = np.linalg.norm(vector2)\n",
    "\n",
    "    # Calculate cosine similarity\n",
    "    similarity = dot_product / (magnitude1 * magnitude2)\n",
    "\n",
    "    return similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Get similar work items to TKT-123', 'get_similar_work_items'),\n",
       " ('Summarize the similar work items', 'summarize_objects'),\n",
       " ('Create issues from the summary', 'create_actionable_tasks_from_text'),\n",
       " ('Prioritize the issues', 'prioritize_objects')]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instructions0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Get objects from customer Cust123', 'search_object_by_name'),\n",
       " ('List all high severity tickets coming in from slack from Cust123',\n",
       "  'works_list'),\n",
       " ('Summarize the high severity tickets', 'summarize_objects')]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instructions1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You are company issue management bot with some tools. Given a tool and a directive you complete the directive using some knowledge. e.g:\n",
      "Directive:Summarize the similar work items\n",
      "Tool:get_similar_work_items with args:\n",
      "\twork_id:The ID of the work item for which you want to find similar items\n",
      "Past Actions/Knowledge:\n",
      "\tGet similar work items to TKT-123:get_similar_work_items\n",
      "\tthe ID of the current User:who_am_i\n",
      "\tthe current sprint:get_current_sprint\n",
      "Output: [(\"work_id\",\"get_similar_work_items\")]\n",
      "\n",
      "Directive:Get my P0 issues\n",
      "Tool:works_list with args:\n",
      "\tapplies_to_part:Filters for work belonging to any of the provided parts.\n",
      "\tcreated_by:Filters for work created by any of these users\n",
      "\towned_by:Filters for work owned by any of these users\n",
      "\tissue.priority:Filters for issues with any of the provided priorities allowing: ['p0', 'p1', 'p2', 'p3']\n",
      "Past Actions/Knowledge:\n",
      "\tthe ID of the current User:who_am_i\n",
      "\tthe current sprint:get_current_sprint\n",
      "Output:[(\"owned_by\",\"who_am_i\"), (\"issue.priority\",\"p0\")]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "base_subtask_prompt = \"\"\"\n",
    "You are company issue management bot. Given a tool and a directive you complete the directive using some knowledge. e.g:\n",
    "Directive:Summarize the similar work items\n",
    "Tool:get_similar_work_items with args:\n",
    "\\twork_id:The ID of the work item for which you want to find similar items\n",
    "Past Actions/Knowledge:\n",
    "\\tGet similar work items to TKT-123:get_similar_work_items\n",
    "\\tthe ID of the current User:who_am_i\n",
    "\\tthe current sprint:get_current_sprint\n",
    "Output: [(\"work_id\",\"get_similar_work_items\")]\n",
    "\n",
    "Directive:Get my P0 issues\n",
    "Tool:works_list with args:\n",
    "\\tapplies_to_part:Filters for work belonging to any of the provided parts.\n",
    "\\tcreated_by:Filters for work created by any of these users\n",
    "\\towned_by:Filters for work owned by any of these users\n",
    "\\tissue.priority:Filters for issues with any of the provided priorities allowing: ['p0', 'p1', 'p2', 'p3']\n",
    "Past Actions/Knowledge:\n",
    "\\tthe ID of the current User:who_am_i\n",
    "\\tthe current sprint:get_current_sprint\n",
    "Output:[(\"owned_by\",\"who_am_i\"), (\"issue.priority\",\"p0\")]\n",
    "\"\"\"\n",
    "print(base_subtask_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Know <the ID of the current sprint from [get_sprint_id]>, Know <the ID of the current user from [who_am_i]>]\n",
      "('Get my work items', 'works_list')\n",
      "[(\"owned_by\",\"who_am_i\"), (\"stage.name\",\"get_current_sprint\")]\n",
      "\n",
      "\n",
      "508.0\n"
     ]
    }
   ],
   "source": [
    "knowledge = []\n",
    "\n",
    "for tool in refined_arguments_description:\n",
    "    if len(refined_arguments_description[tool]) == 0:\n",
    "        tool_names = [t['name'] for t in tools['tools']]\n",
    "        index = tool_names.index(tool)\n",
    "        tool_description = tools['tools'][index]['description'].split('Returns ')[1]\n",
    "        knowledge.append(KnowledgeItem(tool_description, tool))\n",
    "\n",
    "print(knowledge)\n",
    "\n",
    "def elaborate_args(args: list[dict]):\n",
    "    response = \"\"\n",
    "    for arg in args:\n",
    "        for name, props in arg.items():\n",
    "            response += f\"{name}:{props['desc']}\"\n",
    "            if 'allowed' in props.keys():\n",
    "                response += f\" allowing: {props['allowed']}\"\n",
    "            response += \"\\n\\t\"\n",
    "\n",
    "    return response\n",
    "\n",
    "\n",
    "def get_tool_arguments(instruction):\n",
    "    directive = instruction[0]\n",
    "    tool_to_be_used = instruction[1]\n",
    "\n",
    "    tool_arguments = refined_arguments_description[tool_to_be_used]\n",
    "\n",
    "    prompt = base_subtask_prompt + f\"give response for:\\n\"\n",
    "    prompt += f\"Directive:{directive}'\\nTool: {tool_to_be_used} with args:\\n\\t{elaborate_args(tool_arguments)}\"\n",
    "    \n",
    "    prompt += \"\\nPast Actions/Knowledge:\"\n",
    "    for knowledge_item in knowledge[::-1][-4:]:\n",
    "        prompt += f\"\\n\\t{knowledge_item.summarize()}\"\n",
    "\n",
    "    prompt += \"\\nOutput:\"\n",
    "\n",
    "    return prompt\n",
    "\n",
    "total_len = 0\n",
    "\n",
    "for instruction in instructions1:\n",
    "    prompt = get_tool_arguments(instruction)\n",
    "    # print(prompt)\n",
    "    # break\n",
    "    # print(\"\\n\")\n",
    "    total_len += len(prompt)\n",
    "\n",
    "    completion = palm.generate_text(\n",
    "        model=model,\n",
    "        prompt=prompt,\n",
    "        temperature=0,\n",
    "        max_output_tokens=800,\n",
    "    )\n",
    "\n",
    "    print(instruction)\n",
    "    print(completion.result)\n",
    "    print(\"\\n\")\n",
    "\n",
    "    knowledge.append(KnowledgeItem(instruction[0], instruction[1]))\n",
    "\n",
    "print(total_len/4)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'work_id': {'desc': 'The ID of the work item for which you want to find similar items',\n",
       "   'type': 'String',\n",
       "   'example': ['1234567890']}}]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "refined_arguments_description['get_similar_work_items']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "argument_embeddings = json.load(open('argument_embeddings.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query 0.6966728323092024\n"
     ]
    }
   ],
   "source": [
    "directive_embeddings = palm.generate_embeddings(\n",
    "    model=embeddings_model,\n",
    "    text=\"Get parts from customer Cust123\",\n",
    ")\n",
    "\n",
    "for arg in argument_embeddings['search_object_by_name']:\n",
    "    arg_embedding = argument_embeddings['search_object_by_name'][arg]\n",
    "    print(arg, cosine_similarity(arg_embedding, directive_embeddings['embedding']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "\n",
    "doc = nlp(\"Get parts from Cust123\")\n",
    "\n",
    "print([(ent.text, ent.label_) for ent in doc.ents])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[parts, Cust123]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(doc.noun_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\" \".join(map(list(doc.noun_chunks), str())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = refined_arguments_description['works_list']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(palm.list_models())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "argument_embeddings = {}\n",
    "x = None\n",
    "for tool in refined_arguments_description:\n",
    "    argument_embeddings[tool] = {}\n",
    "    for argument in refined_arguments_description[tool]:\n",
    "        for arg, props in argument.items():\n",
    "            argument_ = arg + \":\" + props['desc']\n",
    "            # print(argument_)\n",
    "            embeddings = palm.generate_embeddings(\n",
    "                model=\"models/embedding-gecko-001\",\n",
    "                text=argument_\n",
    "            )\n",
    "            argument_embeddings[tool][arg] = embeddings['embedding']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(argument_embeddings, open('argument_embeddings.json', 'w'), indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_embeddings = palm.generate_embeddings(\n",
    "    model=\"models/embedding-gecko-001\",\n",
    "    text=\"List all high severity tickets them \"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def cosine_similarity(embeddings1, embeddings2):\n",
    "    vector1 = np.array(embeddings1)\n",
    "    vector2 = np.array(embeddings2)\n",
    "\n",
    "    # Calculate dot product\n",
    "    dot_product = np.dot(vector1, vector2)\n",
    "\n",
    "    # Calculate magnitudes\n",
    "    magnitude1 = np.linalg.norm(vector1)\n",
    "    magnitude2 = np.linalg.norm(vector2)\n",
    "\n",
    "    # Calculate cosine similarity\n",
    "    similarity = dot_product / (magnitude1 * magnitude2)\n",
    "\n",
    "    return similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "applies_to_part 0.6344296627448915\n",
      "created_by 0.5870074218989871\n",
      "owned_by 0.6118433946207997\n",
      "issue.rev_orgs 0.660691662266941\n",
      "issue.priority 0.7029635073056274\n",
      "limit 0.6032555833625599\n",
      "stage.name 0.5941191389196038\n",
      "ticket.needs_response 0.7088068220806242\n",
      "ticket.severity 0.8144742037308171\n",
      "ticket.source_channel 0.6731756104675004\n",
      "types 0.6195709153384679\n"
     ]
    }
   ],
   "source": [
    "# import numpy as np\n",
    "\n",
    "for arg in argument_embeddings['works_list']:\n",
    "    arg_embedding = argument_embeddings['works_list'][arg]\n",
    "    print(arg, cosine_similarity(arg_embedding, info_embeddings['embedding']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List all high severity tickets from them\n",
      "applies_to_part : Filters for work belonging to any of the provided parts.\n",
      "[(all high severity tickets, 0.6258663710735963), (them, 0.5119058029487383)]\n",
      "\n",
      "created_by : Filters for work created by any of these users\n",
      "[(all high severity tickets, 0.5973284370231899), (them, 0.44365882280241603)]\n",
      "\n",
      "owned_by : Filters for work owned by any of these users\n",
      "[(all high severity tickets, 0.5853890601086897), (them, 0.42142880469493155)]\n",
      "\n",
      "issue.rev_orgs : Filters for issues with any of the provided Rev organizations\n",
      "[(all high severity tickets, 0.5996469246404537), (them, 0.37242701507888104)]\n",
      "\n",
      "issue.priority : Filters for issues with any of the provided priorities\n",
      "[(all high severity tickets, 0.6185587946715899), (them, 0.39029457688801417)]\n",
      "\n",
      "limit : The maximum number of works to return.\n",
      "[(all high severity tickets, 0.5937899029368208), (them, 0.4160570717768777)]\n",
      "\n",
      "stage.name : Filters for records in the provided stage(s) by name\n",
      "[(all high severity tickets, 0.3557460359282059)]\n",
      "\n",
      "ticket.needs_response : Filters for tickets that need a response\n",
      "[(all high severity tickets, 0.6120306726063237), (them, 0.5126315493948626)]\n",
      "\n",
      "ticket.severity : Filters for tickets with any of the provided severities\n",
      "[(all high severity tickets, 0.6569149834043715), (them, 0.3888706068153)]\n",
      "\n",
      "ticket.source_channel : Filters for tickets with any of the provided source channels\n",
      "[(all high severity tickets, 0.6479007073805757), (them, 0.39455192141321166)]\n",
      "\n",
      "types : Filters for work of the provided types.\n",
      "[(all high severity tickets, 0.5967596566319996), (them, 0.3681279775055831)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(doc2)\n",
    "for arg in args:\n",
    "    for name, props in arg.items():\n",
    "        print(f\"{name} : {props['desc']}\")\n",
    "        relevant_noun_chunks = [(chunk, chunk.similarity(nlp(props['desc']))) for chunk in doc2.noun_chunks if chunk.similarity(nlp(props['desc'])) > 0.3]\n",
    "        print(relevant_noun_chunks)\n",
    "\n",
    "        # print(doc2.noun_chunks[0].similarity(nlp(props['desc'])))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filters for work belonging to any of the provided parts. 0.6678973009450858\n",
      "Filters for work created by any of these users. 0.6391649774712338\n",
      "Filters for work owned by any of these users. 0.6248281978477502\n",
      "Filters for issues with any of the provided Rev organizations. 0.6137762123198153\n",
      "Filters for issues with any of the provided priorities. 0.6312085020893078\n",
      "The maximum number of works to return. 0.6117348495352216\n",
      "Filters for records in the provided stage(s) by name. 0.366006611664165\n",
      "Filters for tickets that need a response. 0.6691003652021462\n",
      "Filters for tickets with any of the provided severities. 0.6597274816160735\n",
      "Filters for tickets with any of the provided source channels. 0.6549307538800886\n",
      "Filters for work of the provided types. 0.5990385488555882\n",
      "The most relevant input field for 'all high severity tickets them' is: ticket.needs_response\n"
     ]
    }
   ],
   "source": [
    "input_fields = {\n",
    "    'applies_to_part': 'Filters for work belonging to any of the provided parts.',\n",
    "    'created_by': 'Filters for work created by any of these users.',\n",
    "    'owned_by': 'Filters for work owned by any of these users.',\n",
    "    'issue.rev_orgs': 'Filters for issues with any of the provided Rev organizations.',\n",
    "    'issue.priority': 'Filters for issues with any of the provided priorities.',\n",
    "    'limit': 'The maximum number of works to return.',\n",
    "    'stage.name': 'Filters for records in the provided stage(s) by name.',\n",
    "    'ticket.needs_response': 'Filters for tickets that need a response.',\n",
    "    'ticket.severity': 'Filters for tickets with any of the provided severities.',\n",
    "    'ticket.source_channel': 'Filters for tickets with any of the provided source channels.',\n",
    "    'types': 'Filters for work of the provided types.'\n",
    "}\n",
    "\n",
    "# Given noun chunk\n",
    "noun_chunk = \"all high severity tickets them\"\n",
    "\n",
    "# Process the noun chunk with spaCy\n",
    "noun_doc = nlp(noun_chunk)\n",
    "\n",
    "# Define a function to calculate similarity between the noun chunk and each input field description\n",
    "def calculate_similarity(description):\n",
    "    x = noun_doc.similarity(nlp(description))\n",
    "    print(description, x)\n",
    "    return x\n",
    "\n",
    "# Find the most relevant input field\n",
    "most_relevant_field = max(input_fields, key=lambda field: calculate_similarity(input_fields[field]))\n",
    "\n",
    "# Print the result\n",
    "print(f\"The most relevant input field for '{noun_chunk}' is: {most_relevant_field}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Filters, issues, any, the provided Rev organizations]"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = nlp('Filters for issues with any of the provided Rev organizations.')\n",
    "list(d.noun_chunks)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
