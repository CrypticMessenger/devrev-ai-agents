# -*- coding: utf-8 -*-
"""React-basic.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1U30GL4JKgnQu3gdRYgZyyhvso9zWYFhP
"""

!pip install langchain

!pip install openai

from langchain.agents import AgentType, initialize_agent, AgentExecutor,Tool, AgentOutputParser, LLMSingleActionAgent
from langchain.schema import AgentAction, AgentFinish, OutputParserException
from langchain.llms import OpenAI
from langchain.prompts import StringPromptTemplate
from typing import List, Union
from langchain.chains import LLMChain
from langchain.tools import tool
import re
from langchain import hub
from langchain.agents.format_scratchpad import format_log_to_str
from langchain.agents.output_parsers import ReActSingleInputOutputParser
from langchain.tools.render import render_text_description

llm = OpenAI(temperature=0, openai_api_key='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')

json_data = {
  "tools": [
    {
      "name": "works_list",
      "description": "Returns a list of work items matching the request",
      "arguments": [
        {
          "name": "applies_to_part",
          "description": "Filters for work belonging to any of the provided parts",
          "type": "array of strings",
          "example": ["FEAT-123", "ENH-123", "PROD-123", "CAPL-123"]
        },
        {
          "name": "created_by",
          "description": "Filters for work created by any of these users",
          "type": "array of strings",
          "example": ["DEVU-123"]
        },
        {
          "name": "issue_priority",
          "description": "Filters for issues with any of the provided priorities. Allowed values: p0, p1, p2, p3",
          "type": "array of strings"
        },
        {
          "name": "issue_rev_orgs",
          "description": "Filters for issues with any of the provided Rev organizations",
          "type": "array of strings",
          "example": ["REV-123"]
        },
        {
          "name": "limit",
          "description": "The maximum number of works to return. The default is '50'",
          "type": "integer (int32)"
        },
        {
          "name": "owned_by",
          "description": "Filters for work owned by any of these users",
          "type": "array of strings",
          "example": ["DEVU-123"]
        },
        {
          "name": "stage_name",
          "description": "Filters for records in the provided stage(s) by name",
          "type": "array of strings"
        }
      ]
    },
    {
      "name": "summarize_objects",
      "description": "Summarizes a list of objects. The logic of how to summarize a particular object type is an internal implementation detail.",
      "arguments": [
        {
          "name": "objects",
          "description": "List of objects to summarize",
          "type": "array of objects"
        }
      ]
    },
    {
      "name": "prioritize_objects",
      "description": "Returns a list of objects sorted by priority. The logic of what constitutes priority for a given object is an internal implementation detail.",
      "arguments": [
        {
          "name": "objects",
          "description": "A list of objects to be prioritized",
          "type": "array of objects"
        }
      ]
    },
    {
      "name": "add_work_items_to_sprint",
      "description": "Adds the given work items to the sprint",
      "arguments": [
        {
          "name": "work_ids",
          "description": "A list of work item IDs to be added to the sprint.",
          "type": "array of strings"
        },
        {
          "name": "sprint_id",
          "description": "The ID of the sprint to which the work items should be added",
          "type": "string"
        }
      ]
    },
    {
      "name": "get_sprint_id",
      "description": "Returns the ID of the current sprint"
    },
    {
      "name": "get_similar_work_items",
      "description": "Returns a list of work items that are similar to the given work item",
      "arguments": [
        {
          "name": "work_id",
          "description": "The ID of the work item for which you want to find similar items",
          "type": "string"
        }
      ]
    },
    {
      "name": "search_object_by_name",
      "description": "Given a search string, returns the id of a matching object in the system of record. If multiple matches are found, it returns the one where the confidence is highest.",
      "arguments": [
        {
          "name": "query",
          "description": "The search string, could be for example customerâ€™s name, part name, user name.",
          "type": "string"
        }
      ]
    },
    {
      "name": "create_actionable_tasks_from_text",
      "description": "Given a text, extracts actionable insights, and creates tasks for them, which are kind of a work item.",
      "arguments": [
        {
          "name": "text",
          "description": "The text from which the actionable insights need to be created.",
          "type": "string"
        }
      ]
    },
    {
      "name": "who_am_i",
      "description": "Returns the ID of the current user"
    }
  ]
}

def generate_functions():
    data = json_data

    all_tool_functions = []
    for tool in data['tools']:
        # Generate function signature
#         @tool('{tool['name']}', handle_tool_error=True)
        function_template = f"def {tool['name']}("

        if 'arguments' in tool:
            arguments = tool['arguments']
            for arg in arguments:
                function_template += f"{arg['name']}=None, "
            function_template = function_template[:-2]  # Remove the trailing comma
        else:
            function_template+= "dummy=None"
        function_template += "):"

        # Generate function description
        function_template += f'\n    """{tool["description"]}"""\n    return "No error. Proceed to next step."'

        # Execute the code in a new namespace
        local_namespace = {}
        exec(function_template, globals(), local_namespace)
        # Create a function object and assign it to the global namespace
        generated_function = local_namespace[tool['name']]
        globals()[tool['name']] = generated_function
        all_tool_functions.append(generated_function)

        print(function_template)
    return all_tool_functions

tools_functions = generate_functions()

tools = []

def create_description(tool):
    desc=tool['description']+" the function take the following arguments - "
    try:
        for args in func['arguments']:
            desc+= f"[argument name - {args['name']}, description = {args['description']}, type = {args['type']}]"
    except:
        pass
    return desc


for i in range(len(json_data['tools'])):
    func = json_data['tools'][i]

    tool = Tool(
        name=func['name'],
        func=tools_functions[i],
        description=create_description(func)
    )
    tools.append(tool)

def query_user(llm_input):
  user_input = input(llm_input)
  return user_input


user_query_tool = Tool(
    name = "query_user",
    func = query_user,
    description = "Use this function to ask user for more some clarification"
)

print(tools+[user_query_tool])

# Set up the base template
template = """You are the helping the chatbot of the company dev-rev. Input question is the query of the user. Answer the following questions as best you can. You have access to the following tools:

{tools}

You can choose to use no tool.
If you feel not enough information is present, Ask the user by query_user tool.
Use the following format:

Question: the input question you must answer
Thought: you should always think about what to do
Action: the action to take, should be one of [{tool_names}]
Action Input: the input'(argument name, argument value)' to the action
Observation: the result of the action
... (this Thought/Action/Action Input/Observation can repeat N times)
Thought: I now know the final answer
Final Answer: for each action 'tool name,'[argument name value]'' '

Example:

Question: Summarize high severity tickets from the customer UltimateCustomer.
Thought: Let's first find the customer "UltimateCustomer".
Action: search_object_by_name
Action Input: (query: "UltimateCustomer")
Observation: No error. Proceed to next step.
Thought: Now that we've located the customer, we need to fetch the high severity tickets related to them.
Action: works_list
Action Input:
(ticket.rev_org: ["$$PREV[0]"] (Referring to the previously retrieved customer ID),
ticket.severity: ["high"],
type: ["ticket"])
Observation: Retrieves a list of high severity tickets associated with the customer "UltimateCustomer".
Thought: To get a better understanding of these high severity tickets, let's summarize 'em.
Action: summarize_objects
Action Input: (objects: "$$PREV[1]") (Referring to the list of high severity tickets)
Observation: Provides a summarized view of the high severity tickets associated with the customer "UltimateCustomer".
Final Answer:
"tool name": "search_object_by_name"
"argument_name": "query"
"argument_value": "UltimateCustomer"
"tool name": "works_list"
"argument_name": "ticket.rev_org"
"argument_value": ["$$PREV[0]"]
"argument_name": "ticket.severity"
"argument_value": ["high"]
"argument_name": "type"
"argument_value": ["ticket"]
"tool name": "summarize_objects"
"argument_name": "objects",
"argument_value": "$$PREV[1]"

Final Answer should contain all the actions(tool name) you took and list of all pairs of argument value and argument name in json as shown above.
Begin! Remember to just output the final result. No blabbering

Question: {input}
{agent_scratchpad}"""

class CustomOutputParser(AgentOutputParser):

    def create_map(self,ans):
        final_ans = []
        lines = ans.split('\n')
        i = 0
        while i < len(lines):
            line = lines[i]
            if line.startswith('"tool name"'):
                tool_name = line.split(":")[1].strip().strip('"')
                i=i+1
                tool_info = {}
                tool_info['tool_name'] = tool_name
                arguments = []
                while i<len(lines):
                    if lines[i].startswith('"tool name"'):
                        break
                    else:
                        argument_name = lines[i].split(":")[1].strip().strip('"')
                        argument_value =  lines[i+1].split(":")[1].strip().strip('"')
                        arguments.append({"argument_name": argument_name, "argument_value":argument_value})
                        i=i+2
                tool_info['arguments']=arguments
                final_ans.append(tool_info)
            else:
                i=i+1
        return final_ans




    def parse(self, llm_output: str) -> Union[AgentAction, AgentFinish]:
        # Check if agent should finish
        if "Final Answer:" in llm_output:
            return AgentFinish(
                # Return values is generally always a dictionary with a single `output` key
                # It is not recommended to try anything else at the moment :)
                return_values={"output": self.create_map(llm_output.split("Final Answer:")[-1].strip())},
                log=llm_output,
            )
        # Parse out the action and action input
        regex = r"Action\s*\d*\s*:(.*?)\nAction\s*\d*\s*Input\s*\d*\s*:[\s]*(.*)"
        match = re.search(regex, llm_output, re.DOTALL)
        if not match:
            raise OutputParserException(f"Could not parse LLM output: `{llm_output}`")
        action = match.group(1).strip()
        action_input = match.group(2)
        # Return the action and action input
        return AgentAction(tool=action, tool_input=action_input.strip(" ").strip('"'), log=llm_output)

prompt = CustomPromptTemplate(
    template=template,
    tools=tools,
    # This omits the `agent_scratchpad`, `tools`, and `tool_names` variables because those are generated dynamically
    # This includes the `intermediate_steps` variable because that is needed
    input_variables=["input", "intermediate_steps"]
)

output_parser = CustomOutputParser()

llm_chain = LLMChain(llm=llm, prompt=prompt)

tool_names = [tool.name for tool in tools]
agent = LLMSingleActionAgent(
    llm_chain=llm_chain,
    output_parser=output_parser,
    stop=["\nObservation:"],
    allowed_tools=tool_names
)

agent_executor = AgentExecutor.from_agent_and_tools(agent=agent, tools=tools, verbose=True)
# agent_executor = initialize_agent(tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True,return_intermediate_steps = True)

agent_executor.agent.llm_chain.prompt.template

output = agent_executor.invoke(
    {
        "input": "Prioritize my p1 work items?"
    }
)
