{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tce3stUlHN0L"
      },
      "source": [
        "##### Copyright 2023 Google LLC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[33mDEPRECATION: Loading egg at /opt/homebrew/lib/python3.11/site-packages/tk-0.1.0-py3.11.egg is deprecated. pip 23.3 will enforce this behaviour change. A possible replacement is to use pip for package installation..\u001b[0m\u001b[33m\n",
            "\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.11 -m pip install --upgrade pip\u001b[0m\n",
            "\u001b[33mDEPRECATION: Loading egg at /opt/homebrew/lib/python3.11/site-packages/tk-0.1.0-py3.11.egg is deprecated. pip 23.3 will enforce this behaviour change. A possible replacement is to use pip for package installation..\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: google-generativeai in /opt/homebrew/lib/python3.11/site-packages (0.2.2)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.3.3 in /opt/homebrew/lib/python3.11/site-packages (from google-generativeai) (0.3.3)\n",
            "Requirement already satisfied: google-auth in /opt/homebrew/lib/python3.11/site-packages (from google-generativeai) (2.25.1)\n",
            "Requirement already satisfied: google-api-core in /opt/homebrew/lib/python3.11/site-packages (from google-generativeai) (2.15.0)\n",
            "Requirement already satisfied: protobuf in /opt/homebrew/lib/python3.11/site-packages (from google-generativeai) (4.25.1)\n",
            "Requirement already satisfied: tqdm in /opt/homebrew/lib/python3.11/site-packages (from google-generativeai) (4.66.1)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.0 in /opt/homebrew/lib/python3.11/site-packages (from google-ai-generativelanguage==0.3.3->google-generativeai) (1.23.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /opt/homebrew/lib/python3.11/site-packages (from google-api-core->google-generativeai) (1.62.0)\n",
            "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /opt/homebrew/lib/python3.11/site-packages (from google-api-core->google-generativeai) (2.31.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/homebrew/lib/python3.11/site-packages (from google-auth->google-generativeai) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/homebrew/lib/python3.11/site-packages (from google-auth->google-generativeai) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/homebrew/lib/python3.11/site-packages (from google-auth->google-generativeai) (4.9)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /opt/homebrew/lib/python3.11/site-packages (from google-api-core->google-generativeai) (1.60.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /opt/homebrew/lib/python3.11/site-packages (from google-api-core->google-generativeai) (1.60.0)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/homebrew/lib/python3.11/site-packages (from pyasn1-modules>=0.2.1->google-auth->google-generativeai) (0.5.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/homebrew/lib/python3.11/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /opt/homebrew/lib/python3.11/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/homebrew/lib/python3.11/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2.0.5)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /opt/homebrew/lib/python3.11/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2023.7.22)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.11 -m pip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade -q google-api-python-client google-auth-httplib2 google-auth-oauthlib\n",
        "!pip install google-generativeai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kWIuwKG2_oWE",
        "outputId": "dff46ad3-e57c-496f-b93f-dfb3613d4e9d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/homebrew/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "# Install the client library and import necessary modules.\n",
        "# !pip install google-generativeai\n",
        "import google.generativeai as palm\n",
        "import base64\n",
        "import json\n",
        "import pprint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "fwiaySnhLyBN"
      },
      "outputs": [],
      "source": [
        "import os.path\n",
        "\n",
        "from google.auth.transport.requests import Request\n",
        "from google.oauth2.credentials import Credentials\n",
        "from google_auth_oauthlib.flow import InstalledAppFlow\n",
        "\n",
        "SCOPES = ['https://www.googleapis.com/auth/generative-language.tuning']\n",
        "\n",
        "def load_creds():\n",
        "    \"\"\"Converts `oauth-client-id.json` to a credential object.\n",
        "\n",
        "    This function caches the generated tokens to minimize the use of the\n",
        "    consent screen.\n",
        "    \"\"\"\n",
        "    creds = None\n",
        "    # The file token.json stores the user's access and refresh tokens, and is\n",
        "    # created automatically when the authorization flow completes for the first\n",
        "    # time.\n",
        "    if os.path.exists('token.json'):\n",
        "        creds = Credentials.from_authorized_user_file('token.json', SCOPES)\n",
        "    # If there are no (valid) credentials available, let the user log in.\n",
        "    if not creds or not creds.valid:\n",
        "        if creds and creds.expired and creds.refresh_token:\n",
        "            creds.refresh(Request())\n",
        "        else:\n",
        "            flow = InstalledAppFlow.from_client_secrets_file(\n",
        "                'oauth-client-id.json', SCOPES)\n",
        "            creds = flow.run_local_server(port=0)\n",
        "        # Save the credentials for the next run\n",
        "        with open('token.json', 'w') as token:\n",
        "            token.write(creds.to_json())\n",
        "    return creds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "id": "v0boEYovL1wQ",
        "outputId": "ca9b799c-45c2-4d47-d025-ba84b2f05b17"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Available base models: ['models/chat-bison-001', 'models/text-bison-001', 'models/embedding-gecko-001']\n",
            "My tuned models: ['tunedModels/trainv1-ck70je33ngb4']\n"
          ]
        }
      ],
      "source": [
        "import pprint\n",
        "import google.generativeai as palm\n",
        "\n",
        "\n",
        "creds = load_creds()\n",
        "\n",
        "palm.configure(credentials=creds)\n",
        "\n",
        "print()\n",
        "print('Available base models:', [m.name for m in palm.list_models()])\n",
        "print('My tuned models:', [m.name for m in palm.list_tuned_models()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Model(name='models/text-bison-001',\n",
              "      base_model_id='',\n",
              "      version='001',\n",
              "      display_name='Text Bison',\n",
              "      description='Model targeted for text generation.',\n",
              "      input_token_limit=8196,\n",
              "      output_token_limit=1024,\n",
              "      supported_generation_methods=['generateText', 'countTextTokens', 'createTunedTextModel'],\n",
              "      temperature=0.7,\n",
              "      top_p=0.95,\n",
              "      top_k=40)"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_name = 'models/text-bison-001'\n",
        "model = palm.get_model(model_name)\n",
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Pwab0i0RAHBN"
      },
      "outputs": [],
      "source": [
        "model = model_name \n",
        "temperature = 0 \n",
        "candidate_count = 1 \n",
        "top_k = 40 \n",
        "top_p = 0.95 \n",
        "max_output_tokens = 1024 \n",
        "\n",
        "defaults = {\n",
        "  'model': model,\n",
        "  'temperature': temperature,\n",
        "  'candidate_count': candidate_count,\n",
        "  'top_k': top_k,\n",
        "  'top_p': top_p,\n",
        "  'max_output_tokens': max_output_tokens,\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_response(prompt, defaults):\n",
        "    \"\"\"Returns the response from the model.\"\"\"\n",
        "    response = palm.generate_text(**defaults,prompt=prompt)\n",
        "    print(response.candidates[0]['output'])\n",
        "    return response,response.candidates[0]['output']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Direct all tools prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'You are the helping the chatbot of the company dev-rev. Input question is the query of the user. Answer the following questions as best you can. You have access to the following tools:\\n\\n{\\'tools\\': [{\\'name\\': \\'works_list\\', \\'description\\': \\'Returns a list of work items matching the request\\', \\'arguments\\': [{\\'name\\': \\'applies_to_part\\', \\'description\\': \\'Filters for work belonging to any of the provided parts\\', \\'type\\': \\'array of strings\\', \\'example\\': [\\'FEAT-123\\', \\'ENH-123\\', \\'PROD-123\\', \\'CAPL-123\\']}, {\\'name\\': \\'created_by\\', \\'description\\': \\'Filters for work created by any of these users\\', \\'type\\': \\'array of strings\\', \\'example\\': [\\'DEVU-123\\']}, {\\'name\\': \\'issue_priority\\', \\'description\\': \\'Filters for issues with any of the provided priorities. Allowed values: p0, p1, p2, p3\\', \\'type\\': \\'array of strings\\'}, {\\'name\\': \\'issue_rev_orgs\\', \\'description\\': \\'Filters for issues with any of the provided Rev organizations\\', \\'type\\': \\'array of strings\\', \\'example\\': [\\'REV-123\\']}, {\\'name\\': \\'limit\\', \\'description\\': \"The maximum number of works to return. The default is \\'50\\'\", \\'type\\': \\'integer (int32)\\'}, {\\'name\\': \\'owned_by\\', \\'description\\': \\'Filters for work owned by any of these users\\', \\'type\\': \\'array of strings\\', \\'example\\': [\\'DEVU-123\\']}, {\\'name\\': \\'stage_name\\', \\'description\\': \\'Filters for records in the provided stage(s) by name\\', \\'type\\': \\'array of strings\\'}]}, {\\'name\\': \\'summarize_objects\\', \\'description\\': \\'Summarizes a list of objects. The logic of how to summarize a particular object type is an internal implementation detail.\\', \\'arguments\\': [{\\'name\\': \\'objects\\', \\'description\\': \\'List of objects to summarize\\', \\'type\\': \\'array of objects\\'}]}, {\\'name\\': \\'prioritize_objects\\', \\'description\\': \\'Returns a list of objects sorted by priority. The logic of what constitutes priority for a given object is an internal implementation detail.\\', \\'arguments\\': [{\\'name\\': \\'objects\\', \\'description\\': \\'A list of objects to be prioritized\\', \\'type\\': \\'array of objects\\'}]}, {\\'name\\': \\'add_work_items_to_sprint\\', \\'description\\': \\'Adds the given work items to the sprint\\', \\'arguments\\': [{\\'name\\': \\'work_ids\\', \\'description\\': \\'A list of work item IDs to be added to the sprint.\\', \\'type\\': \\'array of strings\\'}, {\\'name\\': \\'sprint_id\\', \\'description\\': \\'The ID of the sprint to which the work items should be added\\', \\'type\\': \\'string\\'}]}, {\\'name\\': \\'get_sprint_id\\', \\'description\\': \\'Returns the ID of the current sprint\\'}, {\\'name\\': \\'get_similar_work_items\\', \\'description\\': \\'Returns a list of work items that are similar to the given work item\\', \\'arguments\\': [{\\'name\\': \\'work_id\\', \\'description\\': \\'The ID of the work item for which you want to find similar items\\', \\'type\\': \\'string\\'}]}, {\\'name\\': \\'search_object_by_name\\', \\'description\\': \\'Given a search string, returns the id of a matching object in the system of record. If multiple matches are found, it returns the one where the confidence is highest.\\', \\'arguments\\': [{\\'name\\': \\'query\\', \\'description\\': \\'The search string, could be for example customerâ€™s name, part name, user name.\\', \\'type\\': \\'string\\'}]}, {\\'name\\': \\'create_actionable_tasks_from_text\\', \\'description\\': \\'Given a text, extracts actionable insights, and creates tasks for them, which are kind of a work item.\\', \\'arguments\\': [{\\'name\\': \\'text\\', \\'description\\': \\'The text from which the actionable insights need to be created.\\', \\'type\\': \\'string\\'}]}, {\\'name\\': \\'who_am_i\\', \\'description\\': \\'Returns the ID of the current user\\'}]}\\n\\nYou can choose to use no tool.\\nIf you feel not enough information is present, Ask the user by query_user tool.\\nUse the following format:\\n\\nQuestion: the input question you must answer\\nnow think step by step, and break the Question into multiple actions.\\nFinal Answer: for each action return \"tool_name\",\"argument_name\",\"argument_value\"\\nFor each action, you must search the most relevant sentence in the context, and return the tool name, argument name, argument value.\\n\\n\\nExample:\\n\\nQuestion: Prioritize my P0 issues and add them to the current sprint\\nFinal Answer:\\n\"tool_name\": \"whoami\"\\n\"tool_name\": \"works_list\"\\n\"argument_name\": \"issue.priority\"\\n\"argument_value\": [\"p0\"]\\n\"argument_name\": \"owned_by\"\\n\"argument_value\": [\"$$PREV[0]\"]\\n\"argument_name\": \"type\"\\n\"argument_value\": [\"issue\"]\\n\"tool_name\": \"prioritize_objects\"\\n\"argument_name\": \"objects\"\\n\"argument_value\": \"$$PREV[1]\"\\n\"tool_name\": \"get_sprint_id\"\\n\"tool_name\": \"add_work_items_to_sprint\"\\n\"argument_name\": \"work_ids\"\\n\"argument_value\": \"$$PREV[2]\"\\n\"argument_name\": \"sprint_id\"\\n\"argument_value\": \"$$PREV[3]\"\\n\\nQuestion: Summarize work items similar to don:core:dvrv-us-1:devo/0:issue/1\\nFinal Answer:\\n\"tool_name\": \"get_similar_work_items\"\\n\"argument_name\": \"work_id\"\\n\"argument_value\": \"don:core:dvrv-us-1:devo/0:issue/123\"\\n\"tool_name\": \"summarize_objects\"\\n\"argument_name\": \"objects\"\\n\"argument_value\": \"$$PREV[0]\"\\n\\nFinal Answer should contain all the actions(tool name) you took and list of all pairs of argument value and argument name in above format as shown above.\\nBegin! Remember to just output the final result. No blabbering\\n\\nQuestion: Given a customer meeting\\ntranscript T, create action items\\nand add them to my current sprint'"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# import constants.py from python file \n",
        "from constants import *\n",
        "main_query = f\"\"\"Given a customer meeting\n",
        "transcript T, create action items\n",
        "and add them to my current sprint\"\"\"\n",
        "text = template + main_query\n",
        "\n",
        "text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "LB2LxPmAB95V"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\"tool_name\": \"create_actionable_tasks_from_text\"\n",
            "\"argument_name\": \"text\"\n",
            "\"argument_value\": \"T\"\n",
            "\"tool_name\": \"add_work_items_to_sprint\"\n",
            "\"argument_name\": \"work_ids\"\n",
            "\"argument_value\": \"$$PREV[0]\"\n",
            "\"tool_name\": \"get_sprint_id\"\n"
          ]
        }
      ],
      "source": [
        "# Call the model and print the response.\n",
        "response,unparsed_res = get_response(text, defaults)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[\n",
            "  {\n",
            "    \"tool_name\":\"whoami\",\n",
            "    \"arguments\":[]\n",
            "  },\n",
            "  {\n",
            "    \"tool_name\":\"works_list\",\n",
            "    \"arguments\":[\n",
            "      {\n",
            "        \"argument_name\":\"issue.priority\",\n",
            "        \"argument_value\":[\n",
            "          \"p0\",\n",
            "          \"p1\"\n",
            "        ]\n",
            "      },\n",
            "      {\n",
            "        \"argument_name\":\"owned_by\",\n",
            "        \"argument_value\":[\n",
            "          \"$$PREV[0]\"\n",
            "        ]\n",
            "      },\n",
            "      {\n",
            "        \"argument_name\":\"type\",\n",
            "        \"argument_value\":[\n",
            "          \"issue\"\n",
            "        ]\n",
            "      }\n",
            "    ]\n",
            "  },\n",
            "  {\n",
            "    \"tool_name\":\"prioritize_objects\",\n",
            "    \"arguments\":[\n",
            "      {\n",
            "        \"argument_name\":\"objects\",\n",
            "        \"argument_value\":\"$$PREV[1]\"\n",
            "      }\n",
            "    ]\n",
            "  },\n",
            "  {\n",
            "    \"tool_name\":\"get_sprint_id\",\n",
            "    \"arguments\":[]\n",
            "  },\n",
            "  {\n",
            "    \"tool_name\":\"add_work_items_to_sprint\",\n",
            "    \"arguments\":[\n",
            "      {\n",
            "        \"argument_name\":\"work_ids\",\n",
            "        \"argument_value\":\"$$PREV[2]\"\n",
            "      },\n",
            "      {\n",
            "        \"argument_name\":\"sprint_id\",\n",
            "        \"argument_value\":\"$$PREV[3]\"\n",
            "      }\n",
            "    ]\n",
            "  }\n",
            "]\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "input_data = \"\\\"tool_name\\\": \\\"whoami\\\"\\n\\\"tool_name\\\": \\\"works_list\\\"\\n\\\"argument_name\\\": \\\"issue.priority\\\"\\n\\\"argument_value\\\": [\\\"p0\\\",\\\"p1\\\"]\\n\\\"argument_name\\\": \\\"owned_by\\\"\\n\\\"argument_value\\\": [\\\"$$PREV[0]\\\"]\\n\\\"argument_name\\\": \\\"type\\\"\\n\\\"argument_value\\\": [\\\"issue\\\"]\\n\\\"tool_name\\\": \\\"prioritize_objects\\\"\\n\\\"argument_name\\\": \\\"objects\\\"\\n\\\"argument_value\\\": \\\"$$PREV[1]\\\"\\n\\\"tool_name\\\": \\\"get_sprint_id\\\"\\n\\\"tool_name\\\": \\\"add_work_items_to_sprint\\\"\\n\\\"argument_name\\\": \\\"work_ids\\\"\\n\\\"argument_value\\\": \\\"$$PREV[2]\\\"\\n\\\"argument_name\\\": \\\"sprint_id\\\"\\n\\\"argument_value\\\": \\\"$$PREV[3]\\\"\"\n",
        "\n",
        "# Split the input data into lines\n",
        "lines = input_data.split('\\n')\n",
        "\n",
        "# Initialize variables to store the JSON structure\n",
        "result = []\n",
        "current_tool = None\n",
        "current_arguments = None\n",
        "\n",
        "# Process each line\n",
        "for line in lines:\n",
        "    key, value = map(str.strip, line.split(':', 1))\n",
        "\n",
        "    if key == '\"tool_name\"':\n",
        "        # Start a new tool entry\n",
        "        if current_tool is not None:\n",
        "            result.append({\"tool_name\": current_tool, \"arguments\": current_arguments})\n",
        "        current_tool = value.strip('\"')\n",
        "        current_arguments = []\n",
        "    elif key == '\"argument_name\"':\n",
        "        # Add argument entry to the current tool\n",
        "        current_arguments.append({\"argument_name\": value.strip('\"')})\n",
        "    elif key == '\"argument_value\"':\n",
        "        # Add argument value to the current argument entry\n",
        "        current_arguments[-1][\"argument_value\"] = json.loads(value)\n",
        "\n",
        "# Add the last tool entry\n",
        "if current_tool is not None:\n",
        "    result.append({\"tool_name\": current_tool, \"arguments\": current_arguments})\n",
        "\n",
        "# Convert the result to JSON with custom separators\n",
        "json_result = json.dumps(result, indent=2, separators=(',', ':'))\n",
        "\n",
        "# Print the JSON result\n",
        "print(json_result)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Use tools embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "embeddings_model = \"models/embedding-gecko-001\"\n",
        "palm.configure(api_key='AIzaSyAq9RCFh9Jx5t9oR20xWRAZdXsn-b01pT8')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [],
      "source": [
        "# load json data from file\n",
        "\n",
        "with open('refined_arguments_description.json') as f:\n",
        "    arg_data = json.load(f)\n",
        "with open('tools.json') as f:\n",
        "    tools_desc = json.load(f)\n",
        "# loop through the arg_data and for each key, append the key to the text, and then loop through list to append rest of the text\n",
        "for tool_name in arg_data.keys():\n",
        "    desc = tool_name + \" \" + tools_desc[tool_name] + \" \"\n",
        "    for arg in arg_data[tool_name]:\n",
        "        # get the only key in the dict and append it to the text\n",
        "        arg_name = list(arg.keys())[0]\n",
        "        desc += arg_name + \" \" + arg[arg_name]['desc'] +\" \"+ arg[arg_name]['type'] + \" \"\n",
        "    # create a new json file and store the embedding of description with tool_name as its  like {\"tool_name\": embedding,\"tool_name1\":embedding1}\n",
        "    embedding = palm.generate_embeddings(model=embeddings_model, text=desc)\n",
        "    arg_data[tool_name] = embedding['embedding']\n",
        "\n",
        "# save the embedding data to a json file\n",
        "with open('palm_tool_embeddings.json', 'w') as f:\n",
        "    json.dump(arg_data, f)\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open('palm_tool_embeddings.json') as f:\n",
        "    tools_embeddings = json.load(f)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "works_list :  0.6757864377464744\n",
            "summarize_objects :  0.6059239382265458\n",
            "prioritize_objects :  0.5968038200784628\n",
            "add_work_items_to_sprint :  0.5924900341194972\n",
            "get_sprint_id :  0.5509907598089459\n",
            "get_similar_work_items :  0.5727035330119897\n",
            "search_object_by_name :  0.5541269279159796\n",
            "create_actionable_tasks_from_text :  0.6092875582827902\n",
            "who_am_i :  0.5091437604795548\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import numpy as np\n",
        "query = \"What are my all issues in the triage stage under part FEAT-123? Summarize them.\"\n",
        "target_embedding = palm.generate_embeddings(model=embeddings_model, text=query)['embedding']\n",
        "for tool_name in tools_embeddings.keys():\n",
        "    similar_measure = np.dot(target_embedding, tools_embeddings[tool_name])\n",
        "    print(tool_name,\": \" ,similar_measure)\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "makersuite_text_prompt.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
